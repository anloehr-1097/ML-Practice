{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/ML-Practice/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/ML-Practice/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/ML-Practice/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/ML-Practice/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/ML-Practice/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/ML-Practice/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/ML-Practice/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/ML-Practice/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/ML-Practice/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/ML-Practice/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/ML-Practice/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/ML-Practice/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/ML-Practice/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/ML-Practice/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/ML-Practice/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/ML-Practice/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/ML-Practice/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/ML-Practice/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/ML-Practice/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/ML-Practice/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/w_/7mmc855j2mx35cyh7grs9zsc0000gp/T/ipykernel_75349/2616776673.py\", line 1, in <module>\n",
      "    import torch\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/ML-Practice/lib/python3.11/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/ML-Practice/lib/python3.11/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/ML-Practice/lib/python3.11/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/ML-Practice/lib/python3.11/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/ML-Practice/lib/python3.11/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/usr/local/Caskroom/miniconda/base/envs/ML-Practice/lib/python3.11/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 2., 3.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.Tensor([1,2,2,3])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnc = None \n",
    "\n",
    "membank = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 20])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_loc: int = 10  # N\n",
    "dim_loc: int = 20  # M \n",
    "\n",
    "memmat = torch.rand(size=(n_loc, dim_loc))\n",
    "memmat.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_head -> w_t vec weights with N entries \n",
    "# read_vector r_t = convex combination of mem elements with weights = w_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1])\n",
      "tensor([[0, 0],\n",
      "        [6, 8],\n",
      "        [6, 5],\n",
      "        [9, 2],\n",
      "        [7, 5]])\n",
      "tensor([[0.1000],\n",
      "        [0.2000],\n",
      "        [0.3000],\n",
      "        [0.4000],\n",
      "        [0.5000]])\n",
      "tensor([[0.0000, 0.0000],\n",
      "        [1.2000, 1.6000],\n",
      "        [1.8000, 1.5000],\n",
      "        [3.6000, 0.8000],\n",
      "        [3.5000, 2.5000]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([10.1000,  6.4000])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.arange(0.1,.6,0.1)\n",
    "w = w[:, None]\n",
    "print(w.size())\n",
    "memmat = torch.randint(10, (5,2))\n",
    "print(memmat)\n",
    "print(w)\n",
    "print(w * memmat)\n",
    "torch.sum(w * memmat, dim=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReadHead(torch.nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    def forward(self, mem_mat: torch.Tensor):\n",
    "        \"\"\"Emit read vector r_t\"\"\"\n",
    "        \n",
    "        # product weights w_t\n",
    "        # emit reaad vector r_t\n",
    "        weights = torch.rand(mem_mat.size()[0])\n",
    "        weights = weights[:, None]\n",
    "        return torch.sum(weights * mem_mat, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "rh = ReadHead()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [6, 8],\n",
       "        [6, 5],\n",
       "        [9, 2],\n",
       "        [7, 5]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'gradient'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m rh\u001b[38;5;241m.\u001b[39mforward(memmat)\u001b[38;5;241m.\u001b[39mgradient()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'gradient'"
     ]
    }
   ],
   "source": [
    "\n",
    "rh.forward(memmat).gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WriteHead(torch.nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "    def forward(self, memmat: torch.Tensor):\n",
    "        \"\"\"Write head adjusts memory matrix.\"\"\"\n",
    "\n",
    "        weights = torch.rand(memmat.size()[0])\n",
    "        v_erase =  torch.rand(memmat.size()[1])\n",
    "        v_add =  torch.rand(memmat.size()[1])\n",
    "        weights = weights[:, None]\n",
    "        ones = torch.ones(memmat.size()[1])\n",
    "        for i in range(len(memmat.size()[0])):\n",
    "            memmat[i, :] = memmat[i, :] * (ones - weights[i] * v_erase)\n",
    "            memmat[i, :] = memmat[i, :] * (ones - weights[i] * v_add)\n",
    "\n",
    "        return None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2607, 0.6224, 0.4122],\n",
       "        [0.2607, 0.6224, 0.4122],\n",
       "        [0.2607, 0.6224, 0.4122],\n",
       "        [0.2607, 0.6224, 0.4122]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_mat = e.repeat(4,1)\n",
    "e_mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# free params controller\n",
    "SIZE_OF_MEM = 10\n",
    "NUM_READ_HEADS = 5\n",
    "NUM_WRITE_HEADS = 5\n",
    "LOC_SHIFT_RANGE = list(range(1,6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "class MemoryBank(torch.nn.Module):\n",
    "    def __init__(self, num_vectors: int, vec_dim: int):\n",
    "        super(MemoryBank, self).__init__()\n",
    "        self.num_vec = num_vectors\n",
    "        self.vec_dim = vec_dim\n",
    "        self.data: torch.Tensor | None = None\n",
    "\n",
    "    def init_state(self, batch_size, device):\n",
    "        self.data = torch.zeros(batch_size, self.num_vec, self.vec_dim).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetController(torch.nn.Module):\n",
    "    \"\"\"Some kind of Recurrent net or feedforward net.\"\"\"\n",
    "    # typically LSTM\n",
    "    def __init__(self, h_size=20, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.hidden_size = h_size\n",
    "        self.lstm_cell = torch.nn.LSTM(input_size=1, hidden_size=h_size, batch_first=True)\n",
    "        self.memory_bank: MemoryBank = MemoryBank(10, h_size)\n",
    "\n",
    "    \n",
    "    def forward(self):\n",
    "        # outputs k_t, beta_t, g_t, s_t, \\gamma_t\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "copy_dataset = None\n",
    "sort_dataset = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy dataset \n",
    "copy_vecs = torch.randint(2, (1000, 8))\n",
    "copy_vecs[1, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class CopyDataset(Dataset):\n",
    "    def __init__(self, len, delim: int=-1):\n",
    "        super().__init__()\n",
    "        self.delim = delim\n",
    "        self.data = torch.randint(2, (len, 8))\n",
    "        self.data = torch.column_stack([self.data, torch.ones(self.data.size()[0]) * self.delim])\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        return (self.data[idx, :], self.data[idx, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.,  0.,  0.,  0.,  1.,  1.,  1.,  0., -1.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0.]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cop_data = CopyDataset(10)\n",
    "cop_data[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- for each head, be it a read or write head, the addressing mechanism is implemented\n",
    "=> for each head, the controller needs to produce\n",
    "  + key vector $k_t$\n",
    "  + key strength $\\beta_t$\n",
    "  + interpolation gate $g_t$\n",
    "  + shift weighting $s_t$\n",
    "  + sharpening factor $\\gamma_t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"Tensor\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m3\u001b[39m, (\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m3\u001b[39m, (\u001b[38;5;241m3\u001b[39m,))\n\u001b[0;32m----> 3\u001b[0m x, y, torch\u001b[38;5;241m.\u001b[39mcat([x] \u001b[38;5;241m+\u001b[39m y, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"Tensor\") to list"
     ]
    }
   ],
   "source": [
    "x = torch.randint(3, (5,3))\n",
    "y = torch.randint(3, (3,))\n",
    "x, y, torch.cat([x] + y, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-Practice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
