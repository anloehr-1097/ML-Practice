{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 2., 3.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "t = torch.Tensor([1,2,2,3])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_head -> w_t vec weights with N entries \n",
    "# read_vector r_t = convex combination of mem elements with weights = w_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ReadHead(torch.nn.Module):\n",
    "#     def __init__(self, *args, **kwargs):\n",
    "#         super().__init__(*args, **kwargs)\n",
    "    \n",
    "#     def forward(self, mem_mat: torch.Tensor):\n",
    "#         \"\"\"Emit read vector r_t\"\"\"\n",
    "        \n",
    "#         # product weights w_t\n",
    "#         # emit reaad vector r_t\n",
    "#         weights = torch.rand(mem_mat.size()[0])\n",
    "#         weights = weights[:, None]\n",
    "#         return torch.sum(weights * mem_mat, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class WriteHead(torch.nn.Module):\n",
    "#     def __init__(self, *args, **kwargs):\n",
    "#         super().__init__(*args, **kwargs)\n",
    "#     def forward(self, memmat: torch.Tensor):\n",
    "#         \"\"\"Write head adjusts memory matrix.\"\"\"\n",
    "\n",
    "#         weights = torch.rand(memmat.size()[0])\n",
    "#         v_erase =  torch.rand(memmat.size()[1])\n",
    "#         v_add =  torch.rand(memmat.size()[1])\n",
    "#         weights = weights[:, None]\n",
    "#         ones = torch.ones(memmat.size()[1])\n",
    "#         for i in range(len(memmat.size()[0])):\n",
    "#             memmat[i, :] = memmat[i, :] * (ones - weights[i] * v_erase)\n",
    "#             memmat[i, :] = memmat[i, :] * (ones - weights[i] * v_add)\n",
    "\n",
    "#         return None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# free params controller\n",
    "SIZE_OF_MEM = 10\n",
    "NUM_READ_HEADS = 5\n",
    "NUM_WRITE_HEADS = 5\n",
    "LOC_SHIFT_RANGE = list(range(1,6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "class MemoryBank(torch.nn.Module):\n",
    "    def __init__(self, num_vectors: int, vec_dim: int):\n",
    "        super(MemoryBank, self).__init__()\n",
    "        self.num_vec = num_vectors\n",
    "        self.vec_dim = vec_dim\n",
    "        self.batch_size: Optional[int] = None\n",
    "        self.data: torch.Tensor | None = None\n",
    "\n",
    "    def init_state(self, batch_size, device):\n",
    "        self.batch_size = batch_size\n",
    "        self.data = torch.zeros(batch_size, self.num_vec, self.vec_dim).to(device)\n",
    "\n",
    "    def update(self, weight: torch.Tensor, erase_vec: torch.Tensor, add_vec: torch.Tensor):\n",
    "        # make sure that batch_dim of tensor is indeed self.batch_dim\n",
    "        # TODO check if dims are ok and batch dim is considered correctly\n",
    "        erase_row_stack = erase_vec.repeat(erase_vec.shape[0], 1, self.num_vec).reshape(erase_vec.shape[0], erase_vec.shape[1], -1)\n",
    "        erase_row_stack *= weight\n",
    "        self.data -= erase_row_stack\n",
    "        self.data += weight*add_vec.repeat(add_vec.shape[0], add_vec.shape[1], self.num_vec).reshape(add_vec.shape[0], add_vec.shape[1], -1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 20 10\n",
    "# 4 20\n",
    "\n",
    "20\n",
    "\n",
    "20 10\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.randn(1, 20, 10)\n",
    "r = torch.abs(torch.randn(1, 20)).unsqueeze(-1)\n",
    "r = r / torch.sum(r)\n",
    "r.shape\n",
    "(r * b).sum(1).shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.ones([2,3])\n",
    "t.repeat(1, 3, 1).reshape(t.shape[0], t.shape[1], -1)\n",
    "# torch.ones(size=(3,2))\n",
    "# t, t.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "class NeuralNetController(torch.nn.Module):\n",
    "    \"\"\"Some kind of Recurrent net or feedforward net.\"\"\"\n",
    "    # typically LSTM\n",
    "    def __init__(self, in_size:int=50, h_size: int=20, num_layers: int=1, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.hidden_size: int = h_size\n",
    "        self.inp_size: int = in_size\n",
    "        self.num_lstm_cells: int = num_layers\n",
    "        self.lstm_cell_0 = torch.nn.LSTMCell(\n",
    "            input_size=self.inp_size,\n",
    "            hidden_size=self.hidden_size,\n",
    "            )\n",
    "        # self.memory_bank: MemoryBank = MemoryBank(10, h_size)\n",
    "\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, hidden_state: torch.Tensor, cell_state: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"product hidden vector of size self.hidden_size from input with size self.inp_size.\"\"\"\n",
    "        # outputs k_t, beta_t, g_t, s_t, \\gamma_t\n",
    "        print(f\"x size: {x.shape},\\t h size: {hidden_state.shape},\\t c size: {cell_state.shape}\")\n",
    "        return self.lstm_cell_0(x, (hidden_state, cell_state))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Combinator(torch.nn.Module):\n",
    "    \"\"\"Combine output of controller and memory access to make final prediction.\"\"\"\n",
    "\n",
    "    def __init__(self, hidden_dim: int, read_vec_dim: int=10, num_read_heads: int=1, out_dim: int=10):\n",
    "        \"\"\"Default out dim for copy task: 0 through 9.\"\"\"\n",
    "        super().__init__()\n",
    "        self.hidden_dim: int = hidden_dim\n",
    "        self.read_vec_dim: int = read_vec_dim\n",
    "        self.num_read_heads: int = num_read_heads\n",
    "        self.layer_1: torch.nn.Linear = torch.nn.Linear(\n",
    "            self.hidden_dim + self.read_vec_dim * self.num_read_heads,\n",
    "            out_dim\n",
    "            )\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return torch.argmax(torch.nn.functional.softmax(self.layer_1(x)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Callable\n",
    "class NeuralTuringMachine(torch.nn.Module):\n",
    "    \"\"\"Neural Turing Machine.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_size: int,\n",
    "            out_size: int,\n",
    "            hidden_size: int,\n",
    "            num_mem_vectors: int,\n",
    "            mem_vect_dim: int,\n",
    "            num_read_heads: int,\n",
    "            num_write_heads: int,\n",
    "            num_lstm_layers: int,\n",
    "            sim_func: Callable\n",
    "            ):\n",
    "        super().__init__()\n",
    "        self.inp_size: int = in_size  # input seq dim of each element\n",
    "        self.out_dim: int = out_size # output seq dim of each element\n",
    "        self.hidden_size: int = hidden_size\n",
    "        self.num_mem_vectors: int = num_mem_vectors\n",
    "        self.vect_dim: int = mem_vect_dim\n",
    "        self.num_read_heads: int = num_read_heads\n",
    "        self.num_write_heads: int = num_write_heads\n",
    "        self.membank: MemoryBank = MemoryBank(self.num_mem_vectors, self.vect_dim)\n",
    "        self.controller: NeuralNetController = NeuralNetController(\n",
    "            self.inp_size,\n",
    "            self.hidden_size,\n",
    "            num_layers=num_lstm_layers\n",
    "            )\n",
    "        self.sim_func: Callable[[torch.Tensor, torch.Tensor], torch.Tensor] = sim_func\n",
    "        self.combinator: Combinator = Combinator(\n",
    "            self.hidden_size,\n",
    "            self.vect_dim,\n",
    "            num_read_heads=self.num_read_heads,\n",
    "            out_dim=self.out_dim\n",
    "            )\n",
    "\n",
    "        self.read_heads: List[ReadHead] = [ReadHead(self.hidden_size, self.membank, sim_func=self.sim_func)]\n",
    "        self.write_heads: List[WriteHead] = [WriteHead(self.hidden_size, self.membank, sim_func=self.sim_func)]\n",
    "\n",
    "\n",
    "    def read(self):\n",
    "        pass\n",
    "\n",
    "    def write(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"Tensor of t entries, each entry with dim inp_size.\"\"\"\n",
    "\n",
    "        h_t: torch.Tensor = torch.randn(x.shape[0], self.hidden_size)\n",
    "        c_t: torch.Tensor = torch.randn(x.shape[0], self.hidden_size)\n",
    "        read_vecs: List[torch.Tensor]\n",
    "        out_vals: List = []\n",
    "        # read_vecs: List[torch.Tensor] = [read_head.forward(h_t) for read_head in self.read_heads]\n",
    "\n",
    "        for i in range(x.shape[1]):\n",
    "            # always expect batch dim\n",
    "            print(f\"dim h: {h_t.shape}, dim c: {c_t.shape}\")\n",
    "            h_t, c_t = self.controller.forward(x[:, i:i+1], h_t, c_t)\n",
    "\n",
    "            read_vecs = [read_head.forward(h_t) for read_head in self.read_heads]\n",
    "            read_vec = torch.concat(read_vecs)\n",
    "            out_vals.append(self.combinator.forward(torch.concat([h_t, read_vec], dim=1)))\n",
    "            # update current weights for writing\n",
    "            for write_head in  self.write_heads:\n",
    "                write_head.get_weight()\n",
    "\n",
    "            # update memory \n",
    "            for write_head in  self.write_heads:\n",
    "                write_head.forward(h_t)\n",
    "\n",
    "        return torch.Tensor(out_vals)\n",
    "            \n",
    "\n",
    "    def __call__(self, x: torch.Tensor):\n",
    "        return self.forward(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5])"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "from typing import Tuple, Callable\n",
    "from dataclasses import dataclass\n",
    "\n",
    "class Head(torch.nn.Module):\n",
    "    \"\"\"produce key, key_strength, interpolation_gate, shift_weighting, sharpening_factor.\n",
    "\n",
    "    key in mathbb{R}^{mem_size}\n",
    "    key_strength in mathbb{R}_{+} how sharp the attention to memory locations should be\n",
    "    interpolation_gate in (0,1) how much of last weight should be retained\n",
    "    shift_weighting in mathbb{R}^{num_mem_locations} prob distribution over the num locations\n",
    "    sharpening_factor in [1, infty)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_dim: int,\n",
    "                 membank: MemoryBank,\n",
    "                 sim_func: Callable[[torch.Tensor, torch.Tensor], torch.Tensor]\n",
    "                ):\n",
    "\n",
    "        super().__init__()\n",
    "        self.membank = membank\n",
    "        self.num_mem_locations = self.membank.num_vec\n",
    "        self.sim_func = sim_func\n",
    "        self.mem_size = self.membank.vec_dim\n",
    "        self.current_weight: torch.Tensor = torch.ones(self.num_mem_locations) / self.num_mem_locations # size = num_mem_locations\n",
    "        self.bs: int = 0\n",
    "\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_params(self):\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        ...\n",
    "\n",
    "    def batch_size_infer(self, bs: int):\n",
    "        self.current_weight = self.current_weight.unsqueeze(0)\n",
    "        self.current_weight = self.current_weight.repeat(bs, 1)\n",
    "        self.bs = bs\n",
    "\n",
    "    def get_weight(\n",
    "        self,\n",
    "        k: torch.Tensor,\n",
    "        ks: torch.Tensor,\n",
    "        ig: torch.Tensor,\n",
    "        sw: torch.Tensor,\n",
    "        sf: torch.Tensor\n",
    "        ):\n",
    "        \n",
    "        # print(f\"key.shape: {k.shape}, membank data shape: {self.membank.data.shape}\")\n",
    "        loc_similarity: torch.Tensor = self.sim_func(k, self.membank.data)\n",
    "        loc_similarity = loc_similarity.squeeze(dim=-1)\n",
    "        ks = ks.unsqueeze(1).repeat(1, loc_similarity.shape[1])\n",
    "        # print(f\"loc similarity.shape: {loc_similarity.shape}\")\n",
    "        # print(f\"key strenght shape: {ks.shape}\\t ks * loc_sim shape {(ks*loc_similarity).shape}\")\n",
    "        loc_weight: torch.Tensor = torch.nn.functional.softmax(ks * loc_similarity, dim=1)\n",
    "        # print(f\"loc weight shape {loc_weight.shape}\\t self.current_weight.shape {self.current_weight.shape}\",\n",
    "        #       f\"ig.shape {ig.shape}\")\n",
    "        gated_weighting: torch.Tensor = (1 - ig).unsqueeze(1) * self.current_weight + ig.unsqueeze(1) * loc_weight\n",
    "        compound_weight: torch.Tensor = torch.zeros(self.bs, self.num_mem_locations)\n",
    "\n",
    "        # TODO implement convolution without for loops\n",
    "        # print(f\"sw shape: {sw.shape}.\")\n",
    "        # print(f\"compound weight shape: {compound_weight.shape}.\")\n",
    "\n",
    "        for i in range(self.num_mem_locations):\n",
    "            for j in range(self.num_mem_locations):\n",
    "                compound_weight[:, i] += gated_weighting[:, j] * sw[:, (i-j)%self.num_mem_locations] \n",
    "\n",
    "        print(compound_weight.shape, sf.shape)\n",
    "        sharpened_weight: torch.Tensor = torch.pow(compound_weight, sf.unsqueeze(1).repeat(1, compound_weight.shape[1]))\n",
    "        weight = sharpened_weight / torch.sum(sharpened_weight)\n",
    "        self.current_weight = weight\n",
    "        return weight\n",
    "\n",
    "\n",
    "class ReadHead(Head):\n",
    "    def __init__(self, in_dim, membank, sim_func):\n",
    "        print(membank)\n",
    "        super().__init__(in_dim, membank, sim_func)\n",
    "        self.out_size = self.mem_size + 1 + 1 + self.num_mem_locations + 1\n",
    "        self.layer_1 = torch.nn.Linear(in_features=in_dim, out_features=self.out_size)\n",
    "\n",
    "    def get_params(self, h: torch.Tensor) -> Tuple[torch.Tensor, ...]:\n",
    "        out: torch.Tensor = self.layer_1(h)\n",
    "        read_key: torch.Tensor = out[:, 0 : self.mem_size]\n",
    "        key_strenght: torch.Tensor = torch.exp(out[:, self.mem_size])\n",
    "        # interpolation_gate: torch.Tensor = torch.nn.Sigmoid(out[:, self.mem_size + 1])\n",
    "        interpolation_gate: torch.Tensor = torch.nn.functional.sigmoid(out[:, self.mem_size + 1])\n",
    "        shift_weighting: torch.Tensor = torch.softmax(out[:, (self.mem_size + 2): -1], dim=-1)\n",
    "        sharp_factor: torch.Tensor = 1 + torch.exp(out[:, -1])\n",
    "        return (read_key, key_strenght, interpolation_gate, shift_weighting, sharp_factor)\n",
    "\n",
    "    \n",
    "    def forward(self, h: torch.Tensor):\n",
    "        q_key, key_strength, interpolation_gate, shift_weighting, sharp_factor = self.get_params(h)\n",
    "        weight: torch.Tensor = self.get_weight(q_key, key_strength, interpolation_gate, shift_weighting, sharp_factor)\n",
    "        print(f\"weight shape: {weight.shape}\")\n",
    "        read_vec: torch.Tensor = torch.sum(weight.unsqueeze(-1) * self.membank.data, dim=1)\n",
    "        print(f\"read vec shape: {read_vec.shape}\")\n",
    "        return read_vec\n",
    "\n",
    "\n",
    "class WriteHead(Head):\n",
    "    def __init__(self, in_dim, membank, sim_func):\n",
    "        super().__init__(in_dim, membank, sim_func)\n",
    "        self.out_size: int = self.mem_size * 3 + 1 + 1 + self.num_mem_locations + 1\n",
    "        self.layer_1 = torch.nn.Linear(in_features=in_dim, out_features=self.out_size)\n",
    "\n",
    "    def forward(self, h: torch.Tensor):\n",
    "        params: Tuple[torch.Tensor, ...] = self.get_params(h)\n",
    "        erase_vec: torch.Tensor = params[0]\n",
    "        add_vec: torch.Tensor = params[1]\n",
    "        q_key: torch.Tensor = params[2]\n",
    "        key_strength: torch.Tensor = params[3]\n",
    "        interpolation_gate: torch.Tensor  = params[4]\n",
    "        shift_weighting: torch.Tensor  = params[5]\n",
    "        sharp_factor: torch.Tensor = params[6]\n",
    "        # weight: torch.Tensor = self.get_weight(q_key, key_strength, interpolation_gate, shift_weighting, sharp_factor)\n",
    "        self.membank.update(self.current_weight, erase_vec, add_vec)\n",
    "        return None\n",
    "\n",
    "    def get_params(self, h: torch.Tensor) -> Tuple[torch.Tensor, ...]:\n",
    "        out: torch.Tensor = self.layer_1(h)\n",
    "        erase_vec: torch.Tensor = torch.nn.functional.sigmoid(out[:, :self.mem_size])\n",
    "        add_vec: torch.Tensor = out[:, self.mem_size: 2*self.mem_size]\n",
    "        qkey: torch.Tensor = out[:, self.mem_size: 3*self.mem_size]\n",
    "        key_strength: torch.Tensor = torch.exp(out[:, 3*self.mem_size])\n",
    "        interpolation_gate: torch.Tensor = torch.nn.sigmoid(out[:, 3*self.mem_size + 1])\n",
    "        shift_weighting: torch.Tensor = torch.softmax(out[:, (3*self.mem_size + 2): -1], dim=-1)\n",
    "        sharp_factor: torch.Tensor = 1 + torch.exp(out[:, -1])\n",
    "        return (erase_vec, add_vec, qkey, key_strength, interpolation_gate, shift_weighting, sharp_factor)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "copy_dataset = None\n",
    "sort_dataset = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy dataset \n",
    "copy_vecs = torch.randint(2, (1000, 8))\n",
    "copy_vecs[1, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class CopyDataset(Dataset):\n",
    "    def __init__(self, len, delim: int=-1):\n",
    "        super().__init__()\n",
    "        self.delim = delim\n",
    "        self.length = len\n",
    "        self.data = torch.randint(2, (len, 8))\n",
    "        self.data = torch.column_stack([self.data, torch.ones(self.data.size()[0]) * self.delim])\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        return (self.data[idx, :], self.data[idx, :-1])\n",
    "    def __len__(self) -> int:\n",
    "        return self.length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.,  0.,  1.,  0.,  1.,  1.,  0.,  0., -1.]),\n",
       " tensor([0., 0., 1., 0., 1., 1., 0., 0.]))"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cop_data = CopyDataset(10)\n",
    "\n",
    "cop_data[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- for each head, be it a read or write head, the addressing mechanism is implemented\n",
    "=> for each head, the controller needs to produce\n",
    "  + key vector $k_t$\n",
    "  + key strength $\\beta_t$\n",
    "  + interpolation gate $g_t$\n",
    "  + shift weighting $s_t$\n",
    "  + sharpening factor $\\gamma_t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "ds = DataLoader(cop_data, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 0.,  1.,  0.,  0.,  0.,  1.,  1.,  0., -1.],\n",
      "        [ 0.,  1.,  0.,  1.,  1.,  1.,  0.,  1., -1.]]), tensor([[0., 1., 0., 0., 0., 1., 1., 0.],\n",
      "        [0., 1., 0., 1., 1., 1., 0., 1.]])]\n",
      "torch.Size([2, 9]) tensor([[ 0.,  1.,  0.,  0.,  0.,  1.,  1.,  0., -1.],\n",
      "        [ 0.,  1.,  0.,  1.,  1.,  1.,  0.,  1., -1.]])\n",
      "torch.Size([2, 8]) tensor([[0., 1., 0., 0., 0., 1., 1., 0.],\n",
      "        [0., 1., 0., 1., 1., 1., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "for i, obj in enumerate(ds):\n",
    "    if i < 1:\n",
    "        print(obj)\n",
    "        print(obj[0].shape, obj[0])\n",
    "        print(obj[1].shape, obj[1])\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(ntm: NeuralTuringMachine, ds: CopyDataset, loss_func: Callable = None, epochs: int=10, bs: int = 4):\n",
    "    dataloader = DataLoader(ds, batch_size=bs)\n",
    "    adam = torch.optim.Adam(ntm.parameters())\n",
    "    ntm.membank.init_state(bs, torch.device(\"cpu\"))\n",
    "    for rh in ntm.read_heads:\n",
    "        rh.batch_size_infer(bs)\n",
    "\n",
    "\n",
    "    for i in range(epochs):\n",
    "        for ep, (x,y) in enumerate(dataloader):\n",
    "            adam.zero_grad()\n",
    "            print(f\"x: {x}, shape: {x.shape}\")\n",
    "            pred = ntm(x)\n",
    "            loss = loss_func(pred,y)\n",
    "            loss.backward()\n",
    "            adam.step()\n",
    "            print(loss)\n",
    "\n",
    "        print(f\"Finished epoch no {ep}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.6453, -1.9508])"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dot_product(t1: torch.Tensor, t2: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.sum(t1 * t2, dim=1)\n",
    "t1 = torch.randn(2, 10)\n",
    "t2 = torch.randn(2, 10)\n",
    "\n",
    "dot_product(t1, t2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2.0068e-01],\n",
       "         [1.5779e-03],\n",
       "         [8.6358e-03],\n",
       "         [2.9689e-03],\n",
       "         [5.3717e-02],\n",
       "         [2.4518e-04],\n",
       "         [1.6183e-03],\n",
       "         [2.0148e-01],\n",
       "         [3.3282e-04],\n",
       "         [2.2563e-02],\n",
       "         [8.6456e-03],\n",
       "         [1.8847e-02],\n",
       "         [3.0825e-01],\n",
       "         [5.0610e-02],\n",
       "         [6.2993e-03],\n",
       "         [1.0062e-01],\n",
       "         [1.1395e-04],\n",
       "         [6.8084e-03],\n",
       "         [5.2486e-03],\n",
       "         [7.4083e-04]]),\n",
       " torch.Size([4, 20, 1]))"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def new_dot_prod(k: torch.Tensor, mb: torch.Tensor):\n",
    "    # key.shape = (batch_size, size_of_mem_vector)\n",
    "    # mb.shape = (batch_size, num_mem_vectors, size_of_mem_vector)\n",
    "    k = k.unsqueeze(1)\n",
    "    k = k.repeat(1,20,1)\n",
    "    # print(k.shape)\n",
    "    # print(k[0, :, :])\n",
    "    # print(mb.shape)\n",
    "\n",
    "    prod = k * mb\n",
    "    return torch.sum(prod, dim=2, keepdim=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "t1 = torch.randn((4, 10))\n",
    "t2 = torch.randn((4, 20, 10))\n",
    "\n",
    "\n",
    "dp = new_dot_prod(t1, t2)\n",
    "\n",
    "torch.softmax(dp, dim=1)[0], dp.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MemoryBank()\n"
     ]
    }
   ],
   "source": [
    "ntm = NeuralTuringMachine(1, 10, 20, 20, 10, 1, 1, 1, new_dot_prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5000,  1.0000,  1.5000,  2.0000,  2.5000,  3.0000,  3.5000,  4.0000,\n",
       "          4.5000,  5.0000,  5.5000,  6.0000,  6.5000,  7.0000,  7.5000,  8.0000,\n",
       "          8.5000,  9.0000,  9.5000, 10.0000],\n",
       "        [ 0.5000,  1.0000,  1.5000,  2.0000,  2.5000,  3.0000,  3.5000,  4.0000,\n",
       "          4.5000,  5.0000,  5.5000,  6.0000,  6.5000,  7.0000,  7.5000,  8.0000,\n",
       "          8.5000,  9.0000,  9.5000, 10.0000],\n",
       "        [ 0.5000,  1.0000,  1.5000,  2.0000,  2.5000,  3.0000,  3.5000,  4.0000,\n",
       "          4.5000,  5.0000,  5.5000,  6.0000,  6.5000,  7.0000,  7.5000,  8.0000,\n",
       "          8.5000,  9.0000,  9.5000, 10.0000],\n",
       "        [ 0.5000,  1.0000,  1.5000,  2.0000,  2.5000,  3.0000,  3.5000,  4.0000,\n",
       "          4.5000,  5.0000,  5.5000,  6.0000,  6.5000,  7.0000,  7.5000,  8.0000,\n",
       "          8.5000,  9.0000,  9.5000, 10.0000]])"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ra = torch.arange(1,21)\n",
    "ra = ra.unsqueeze(0).repeat(4,1)\n",
    "fac = torch.ones(4)*0.5\n",
    "fac.unsqueeze(1) * ra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[ 0.,  1.,  0.,  0.,  0.,  1.,  1.,  0., -1.],\n",
      "        [ 0.,  1.,  0.,  1.,  1.,  1.,  0.,  1., -1.],\n",
      "        [ 0.,  0.,  0.,  1.,  1.,  0.,  0.,  0., -1.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.,  1.,  1., -1.]]), shape: torch.Size([4, 9])\n",
      "dim h: torch.Size([4, 20]), dim c: torch.Size([4, 20])\n",
      "x size: torch.Size([4, 1]),\t h size: torch.Size([4, 20]),\t c size: torch.Size([4, 20])\n",
      "torch.Size([4, 20]) torch.Size([4])\n",
      "weight shape: torch.Size([4, 20])\n",
      "read vec shape: torch.Size([4, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lr/2zwst7m50b9gcy2vmd1l7bwm0000gn/T/ipykernel_41515/1526252897.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return torch.argmax(torch.nn.functional.softmax(self.layer_1(x)))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Head.get_weight() missing 5 required positional arguments: 'k', 'ks', 'ig', 'sw', and 'sf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[442], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mntm\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcop_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[437], line 13\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(ntm, ds, loss_func, epochs, bs)\u001b[0m\n\u001b[1;32m     11\u001b[0m adam\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mntm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_func(pred,y)\n\u001b[1;32m     15\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Cell \u001b[0;32mIn[428], line 78\u001b[0m, in \u001b[0;36mNeuralTuringMachine.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[428], line 68\u001b[0m, in \u001b[0;36mNeuralTuringMachine.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# update current weights for writing\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m write_head \u001b[38;5;129;01min\u001b[39;00m  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_heads:\n\u001b[0;32m---> 68\u001b[0m     \u001b[43mwrite_head\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# update memory \u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m write_head \u001b[38;5;129;01min\u001b[39;00m  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_heads:\n",
      "\u001b[0;31mTypeError\u001b[0m: Head.get_weight() missing 5 required positional arguments: 'k', 'ks', 'ig', 'sw', and 'sf'"
     ]
    }
   ],
   "source": [
    "train(ntm , cop_data, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-practice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
