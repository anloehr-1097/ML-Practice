{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Optional, Dict, List\n",
    "import random\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torchvision.transforms.functional import pil_to_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "# help(MNIST)\n",
    "\n",
    "mnist_data =  MNIST(root=\".\", download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APAACzBVBJJwAO9dnp/wm8damu6Dw5dRjGf9IKw/+hkVPffCnWNJa7XVNV0Kxa1hErrNe/M2cnYqgElsAHpjkc1wlAODkV694W8c654t8M6n4TuvEctrrFw0cun3c0/lq+3AMJcDK5AyOeTkd+fPvGFn4gsvEtzF4m89tUG1ZJJjuMgUBVYN/EMKOe9YVXtK0bUtdvVs9LsZ7y4YgbIULYycZPoPc8V6lpfwh0/w7p66z8RdXj0y2z8llC4aWQ+mRn8lz9RXPfE3x1pvi46TYaPZTQadpMJghluWDSyrhQM9SMBe5Oc5NcBV7Tda1XRZJJNK1O8sXkG12tZ2iLD0JUjNQ3l9eahN517dT3MvTfNIXb16n6mq9Ff/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA90lEQVR4AWNgGMyAWUhIqK5jvdSy/9/rQe5kgTlWjs3KRiAYxHsyKfDzxYMgFiOIAALDvfwQBsO/pK8Mz97fhPLAlNDtvyBwbNv3j8jCUHbAnOy/f89yM2jPwiLJwMc4628UqgQTnPvp/0eGFAQXLg5lcO/764YuhuArf3y4IAfmfoQwlBX44e/fckkMYaiA7q6/f6dJ45IViP3zdzcuSQaGn39/OkBl4WEL4euFmLIwXDuETav6lKfAIPy1DYucRNFdUPCe9MOUE3e6CpI6FogZSEKrwbFyOIATQ5v5mkcgXV9auVGlwK4NDGRguL75b88HVDla8QBFF16ADQA8sQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, torch.Size([28, 28]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist_data)\n",
    "sample = mnist_data[0]\n",
    "MNIST_SIZE = pil_to_tensor(sample[0]).size()[1:]\n",
    "\n",
    "display(sample[0]), print(sample[1]), MNIST_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_img(img: \"Image\"):\n",
    "    intermediate_img: Tensor = pil_to_tensor(img)\n",
    "    return intermediate_img / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logger = logging.getLogger(\"This\")\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# TODO change all layer to torch.nn.LAYERTYPE\n",
    "\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        # self.inp_layer: Tensor =  torch.rand(size=(MNIST_SIZE[0] * MNIST_SIZE[1], 20)).to(float)  # hidden dim=20\n",
    "        self.inp_layer: Tensor =  torch.nn.Linear(in_features=MNIST_SIZE[0] * MNIST_SIZE[1], out_features=20)\n",
    "        # self.bias1: Tensor = torch.rand(20)\n",
    "        # self.layer2_mu: Tensor = torch.rand(size=(20, 5)).to(float)\n",
    "        self.layer2_mu: Tensor = torch.nn.Linear(in_features=20, out_features=5)\n",
    "        # self.layer2_sigma: Tensor = torch.rand(size=(20, 5)).to(float)\n",
    "        self.layer2_sigma: Tensor = torch.nn.Linear(in_features=20, out_features=5)\n",
    "        # self.bias2_mu: Tensor = torch.rand(size=(1, 5))\n",
    "        # self.bias2_sigma: Tensor = torch.rand(size=(1, 5))\n",
    "        self.distr: Optional[torch.distributions.Normal] = None\n",
    "        return None\n",
    "\n",
    "    def __forward__(self, x: Tensor):\n",
    "        # encoder returns mu and log sigma^2\n",
    "        x = self.inp_layer(x)\n",
    "        x = torch.functional.F.tanh(x)\n",
    "        mu = self.layer2_mu(x)\n",
    "        log_sigma = self.layer2_sigma(x)\n",
    "        return (mu, log_sigma)\n",
    "\n",
    "    def __call__(self, x: Tensor):\n",
    "        return self.__forward__(x)\n",
    "\n",
    "\n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        # 5 -> 100\n",
    "        # 100 -> 784\n",
    "        self.inp_layer: torch.nn.Linear = torch.nn.Linear(in_features=5, out_features=100)\n",
    "        self.layer_1_mu: torch.nn.Linear = torch.nn.Linear(in_features=100, out_features=784)\n",
    "        self.layer_1_sigma: torch.nn.Linear = torch.nn.Linear(in_features=100, out_features=784)\n",
    "        return None\n",
    "        \n",
    "    def __forward__(self, x: Tensor):\n",
    "        logger.info(x.size())\n",
    "        x = self.inp_layer(x)\n",
    "        logger.info(x.size())\n",
    "        x = torch.functional.F.tanh(x)\n",
    "        logger.info(x.size())\n",
    "        mu = self.layer_1_mu(x)\n",
    "        log_sigma = self.layer_1_sigma(x)\n",
    "        logger.info((mu.size(), log_sigma.size()))\n",
    "        return (mu, log_sigma)\n",
    "\n",
    "    def __call__(self, x: Tensor):\n",
    "        return self.__forward__(x)\n",
    "\n",
    "class VAE(torch.nn.Module):\n",
    "    def __init__(self, enc: Encoder, dec: Decoder):\n",
    "        super(VAE, self).__init__()\n",
    "        self.enc = enc\n",
    "        self.dec = dec\n",
    "\n",
    "    def __forward__(self, x: Tensor) -> Tensor:\n",
    "        x_enc: Tuple[Tensor, Tensor] =  self.enc(x)\n",
    "        latent_norm_enc: Dict[str, Tensor] = {\"loc\": x_enc[0], \"scale\": torch.exp(x_enc[1])}\n",
    "        latent_distr: torch.distributions.Normal  = torch.distributions.Normal(**latent_norm_enc)\n",
    "        latent_var: Tensor = latent_distr.rsample()\n",
    "        reconstr_norm_dec: Tuple[Tensor, Tensor] = self.dec(latent_var.T)\n",
    "        reconstr_norm_params: Dict[str, Tensor] = {\"loc\": reconstr_norm_dec[0], \"scale\": torch.exp(reconstr_norm_dec[1])}\n",
    "        reconstr_distr: torch.distributions.Normal = torch.distributions.Normal(**reconstr_norm_params)\n",
    "        reconstr_var: Tensor = reconstr_distr.rsample()\n",
    "        return reconstr_var\n",
    "\n",
    "    def __call__(self, x: Tensor):\n",
    "        return self.__forward__(x)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "enc = Encoder()\n",
    "some_index: int = random.randint(0, len(mnist_data))\n",
    "img_tens = transform_img(mnist_data[some_index][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([20, 784]),\n",
       " torch.Size([20]),\n",
       " torch.Size([5, 20]),\n",
       " torch.Size([5]),\n",
       " torch.Size([5, 20]),\n",
       " torch.Size([5])]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encods = Encoder()\n",
    "[p.size() for p in encods.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_tens.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y  = enc(img_tens.flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.1722, -0.1544, -0.0072, -0.2497,  0.0809], grad_fn=<ViewBackward0>),\n",
       " tensor([ 0.0234,  0.3458, -0.0679, -0.1106,  0.0207], grad_fn=<ViewBackward0>))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = y[0]\n",
    "# log_sigma = torch.eye(5) * y[1]\n",
    "log_sigma = y[1]\n",
    "sigma = torch.exp(log_sigma)\n",
    "\n",
    "mu, sigma\n",
    "z = torch.normal(mean=mu, std=sigma).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-1.3429, -1.4355, -0.7011, -0.6105,  1.0039],\n",
       "        grad_fn=<PermuteBackward0>),\n",
       " torch.Size([5]))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z, z.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0265, -0.0191,  0.0340,  ...,  0.0013,  0.0147,  0.0060],\n",
       "         [-0.0133, -0.0011, -0.0214,  ..., -0.0345,  0.0152,  0.0313],\n",
       "         [ 0.0186,  0.0219, -0.0187,  ..., -0.0147, -0.0283, -0.0029],\n",
       "         ...,\n",
       "         [-0.0219, -0.0338,  0.0340,  ...,  0.0315, -0.0309, -0.0183],\n",
       "         [-0.0147,  0.0041,  0.0132,  ..., -0.0085, -0.0153,  0.0122],\n",
       "         [ 0.0271, -0.0001,  0.0192,  ...,  0.0011,  0.0060,  0.0075]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0158, -0.0321, -0.0327,  0.0009, -0.0135,  0.0202, -0.0176, -0.0132,\n",
       "         -0.0176, -0.0054, -0.0336, -0.0247, -0.0088,  0.0004,  0.0147, -0.0135,\n",
       "          0.0315,  0.0091,  0.0161,  0.0264], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.2019,  0.0622,  0.1885,  0.0049,  0.0841,  0.1094, -0.0787, -0.1684,\n",
       "           0.0392, -0.0969,  0.1122,  0.1654, -0.1452,  0.0725, -0.0699, -0.1403,\n",
       "           0.1898, -0.1609, -0.1196,  0.2111],\n",
       "         [ 0.0416, -0.1385,  0.0138,  0.1562,  0.1723,  0.0977, -0.1678, -0.2200,\n",
       "          -0.0055,  0.1614, -0.0914,  0.1265,  0.0062, -0.0216,  0.1860,  0.0173,\n",
       "          -0.1687,  0.1772, -0.2006,  0.1510],\n",
       "         [-0.0581, -0.0852,  0.1097,  0.1337,  0.0055,  0.0238,  0.1928,  0.1790,\n",
       "          -0.1128,  0.0905,  0.2144,  0.1747, -0.2107, -0.2121,  0.1121,  0.1134,\n",
       "          -0.2019,  0.1364, -0.0182, -0.1926],\n",
       "         [-0.1500, -0.1017,  0.1512,  0.2230,  0.0149,  0.1709,  0.1932,  0.1046,\n",
       "           0.1970, -0.2100,  0.1570, -0.1485,  0.0007, -0.2225,  0.1022, -0.1527,\n",
       "          -0.1912, -0.0762,  0.1139,  0.0398],\n",
       "         [ 0.1396,  0.0828,  0.2005, -0.0993,  0.1895,  0.0895,  0.0364, -0.0004,\n",
       "           0.0210, -0.0866, -0.0478,  0.1193,  0.0443, -0.2143,  0.1356, -0.1938,\n",
       "           0.0356, -0.1608, -0.0677, -0.1993]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.1879, -0.1695,  0.0951, -0.0494,  0.1524], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.1502,  0.0882,  0.1418, -0.1485, -0.0137,  0.1215,  0.0245, -0.1440,\n",
       "          -0.0421,  0.1104, -0.0843,  0.0527, -0.2014, -0.1348,  0.0023, -0.1438,\n",
       "          -0.0539,  0.1194, -0.1653, -0.0056],\n",
       "         [-0.2141, -0.1714, -0.0191,  0.2222,  0.0712, -0.1873, -0.0314, -0.1293,\n",
       "          -0.1697,  0.1320,  0.0501, -0.1604, -0.2058,  0.0194,  0.1579, -0.1385,\n",
       "           0.0087, -0.1558,  0.1492,  0.0880],\n",
       "         [ 0.0252,  0.0278,  0.1402, -0.1567, -0.0886,  0.0320,  0.2092, -0.1916,\n",
       "           0.2120, -0.1528,  0.1569,  0.1315, -0.1469, -0.1962,  0.0763, -0.1062,\n",
       "           0.0937, -0.0926, -0.0758,  0.1865],\n",
       "         [ 0.0086, -0.0257, -0.0097,  0.1973, -0.1210, -0.0935,  0.1735, -0.1644,\n",
       "           0.0030, -0.1249, -0.0033,  0.1789, -0.0548,  0.2137,  0.1253,  0.1511,\n",
       "          -0.2066, -0.1164, -0.0658,  0.1530],\n",
       "         [-0.1431,  0.0753,  0.0163,  0.0393,  0.1437,  0.0045, -0.0790, -0.1866,\n",
       "           0.0604,  0.1212, -0.0738,  0.1627, -0.1879, -0.0519, -0.0821,  0.0293,\n",
       "           0.0941,  0.2002,  0.2052,  0.0487]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.1535,  0.2159,  0.1678, -0.1466,  0.0177], requires_grad=True)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enc.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([784]) torch.Size([784])\n"
     ]
    }
   ],
   "source": [
    "dec = Decoder()\n",
    "\n",
    "tilde_x = dec(z)\n",
    "print(tilde_x[0].size(), tilde_x[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(enc, dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0265, -0.0191,  0.0340,  ...,  0.0013,  0.0147,  0.0060],\n",
       "         [-0.0133, -0.0011, -0.0214,  ..., -0.0345,  0.0152,  0.0313],\n",
       "         [ 0.0186,  0.0219, -0.0187,  ..., -0.0147, -0.0283, -0.0029],\n",
       "         ...,\n",
       "         [-0.0219, -0.0338,  0.0340,  ...,  0.0315, -0.0309, -0.0183],\n",
       "         [-0.0147,  0.0041,  0.0132,  ..., -0.0085, -0.0153,  0.0122],\n",
       "         [ 0.0271, -0.0001,  0.0192,  ...,  0.0011,  0.0060,  0.0075]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0158, -0.0321, -0.0327,  0.0009, -0.0135,  0.0202, -0.0176, -0.0132,\n",
       "         -0.0176, -0.0054, -0.0336, -0.0247, -0.0088,  0.0004,  0.0147, -0.0135,\n",
       "          0.0315,  0.0091,  0.0161,  0.0264], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.2019,  0.0622,  0.1885,  0.0049,  0.0841,  0.1094, -0.0787, -0.1684,\n",
       "           0.0392, -0.0969,  0.1122,  0.1654, -0.1452,  0.0725, -0.0699, -0.1403,\n",
       "           0.1898, -0.1609, -0.1196,  0.2111],\n",
       "         [ 0.0416, -0.1385,  0.0138,  0.1562,  0.1723,  0.0977, -0.1678, -0.2200,\n",
       "          -0.0055,  0.1614, -0.0914,  0.1265,  0.0062, -0.0216,  0.1860,  0.0173,\n",
       "          -0.1687,  0.1772, -0.2006,  0.1510],\n",
       "         [-0.0581, -0.0852,  0.1097,  0.1337,  0.0055,  0.0238,  0.1928,  0.1790,\n",
       "          -0.1128,  0.0905,  0.2144,  0.1747, -0.2107, -0.2121,  0.1121,  0.1134,\n",
       "          -0.2019,  0.1364, -0.0182, -0.1926],\n",
       "         [-0.1500, -0.1017,  0.1512,  0.2230,  0.0149,  0.1709,  0.1932,  0.1046,\n",
       "           0.1970, -0.2100,  0.1570, -0.1485,  0.0007, -0.2225,  0.1022, -0.1527,\n",
       "          -0.1912, -0.0762,  0.1139,  0.0398],\n",
       "         [ 0.1396,  0.0828,  0.2005, -0.0993,  0.1895,  0.0895,  0.0364, -0.0004,\n",
       "           0.0210, -0.0866, -0.0478,  0.1193,  0.0443, -0.2143,  0.1356, -0.1938,\n",
       "           0.0356, -0.1608, -0.0677, -0.1993]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.1879, -0.1695,  0.0951, -0.0494,  0.1524], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.1502,  0.0882,  0.1418, -0.1485, -0.0137,  0.1215,  0.0245, -0.1440,\n",
       "          -0.0421,  0.1104, -0.0843,  0.0527, -0.2014, -0.1348,  0.0023, -0.1438,\n",
       "          -0.0539,  0.1194, -0.1653, -0.0056],\n",
       "         [-0.2141, -0.1714, -0.0191,  0.2222,  0.0712, -0.1873, -0.0314, -0.1293,\n",
       "          -0.1697,  0.1320,  0.0501, -0.1604, -0.2058,  0.0194,  0.1579, -0.1385,\n",
       "           0.0087, -0.1558,  0.1492,  0.0880],\n",
       "         [ 0.0252,  0.0278,  0.1402, -0.1567, -0.0886,  0.0320,  0.2092, -0.1916,\n",
       "           0.2120, -0.1528,  0.1569,  0.1315, -0.1469, -0.1962,  0.0763, -0.1062,\n",
       "           0.0937, -0.0926, -0.0758,  0.1865],\n",
       "         [ 0.0086, -0.0257, -0.0097,  0.1973, -0.1210, -0.0935,  0.1735, -0.1644,\n",
       "           0.0030, -0.1249, -0.0033,  0.1789, -0.0548,  0.2137,  0.1253,  0.1511,\n",
       "          -0.2066, -0.1164, -0.0658,  0.1530],\n",
       "         [-0.1431,  0.0753,  0.0163,  0.0393,  0.1437,  0.0045, -0.0790, -0.1866,\n",
       "           0.0604,  0.1212, -0.0738,  0.1627, -0.1879, -0.0519, -0.0821,  0.0293,\n",
       "           0.0941,  0.2002,  0.2052,  0.0487]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.1535,  0.2159,  0.1678, -0.1466,  0.0177], requires_grad=True)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enc.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0265, -0.0191,  0.0340,  ...,  0.0013,  0.0147,  0.0060],\n",
       "         [-0.0133, -0.0011, -0.0214,  ..., -0.0345,  0.0152,  0.0313],\n",
       "         [ 0.0186,  0.0219, -0.0187,  ..., -0.0147, -0.0283, -0.0029],\n",
       "         ...,\n",
       "         [-0.0219, -0.0338,  0.0340,  ...,  0.0315, -0.0309, -0.0183],\n",
       "         [-0.0147,  0.0041,  0.0132,  ..., -0.0085, -0.0153,  0.0122],\n",
       "         [ 0.0271, -0.0001,  0.0192,  ...,  0.0011,  0.0060,  0.0075]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0158, -0.0321, -0.0327,  0.0009, -0.0135,  0.0202, -0.0176, -0.0132,\n",
       "         -0.0176, -0.0054, -0.0336, -0.0247, -0.0088,  0.0004,  0.0147, -0.0135,\n",
       "          0.0315,  0.0091,  0.0161,  0.0264], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.2019,  0.0622,  0.1885,  0.0049,  0.0841,  0.1094, -0.0787, -0.1684,\n",
       "           0.0392, -0.0969,  0.1122,  0.1654, -0.1452,  0.0725, -0.0699, -0.1403,\n",
       "           0.1898, -0.1609, -0.1196,  0.2111],\n",
       "         [ 0.0416, -0.1385,  0.0138,  0.1562,  0.1723,  0.0977, -0.1678, -0.2200,\n",
       "          -0.0055,  0.1614, -0.0914,  0.1265,  0.0062, -0.0216,  0.1860,  0.0173,\n",
       "          -0.1687,  0.1772, -0.2006,  0.1510],\n",
       "         [-0.0581, -0.0852,  0.1097,  0.1337,  0.0055,  0.0238,  0.1928,  0.1790,\n",
       "          -0.1128,  0.0905,  0.2144,  0.1747, -0.2107, -0.2121,  0.1121,  0.1134,\n",
       "          -0.2019,  0.1364, -0.0182, -0.1926],\n",
       "         [-0.1500, -0.1017,  0.1512,  0.2230,  0.0149,  0.1709,  0.1932,  0.1046,\n",
       "           0.1970, -0.2100,  0.1570, -0.1485,  0.0007, -0.2225,  0.1022, -0.1527,\n",
       "          -0.1912, -0.0762,  0.1139,  0.0398],\n",
       "         [ 0.1396,  0.0828,  0.2005, -0.0993,  0.1895,  0.0895,  0.0364, -0.0004,\n",
       "           0.0210, -0.0866, -0.0478,  0.1193,  0.0443, -0.2143,  0.1356, -0.1938,\n",
       "           0.0356, -0.1608, -0.0677, -0.1993]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.1879, -0.1695,  0.0951, -0.0494,  0.1524], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.1502,  0.0882,  0.1418, -0.1485, -0.0137,  0.1215,  0.0245, -0.1440,\n",
       "          -0.0421,  0.1104, -0.0843,  0.0527, -0.2014, -0.1348,  0.0023, -0.1438,\n",
       "          -0.0539,  0.1194, -0.1653, -0.0056],\n",
       "         [-0.2141, -0.1714, -0.0191,  0.2222,  0.0712, -0.1873, -0.0314, -0.1293,\n",
       "          -0.1697,  0.1320,  0.0501, -0.1604, -0.2058,  0.0194,  0.1579, -0.1385,\n",
       "           0.0087, -0.1558,  0.1492,  0.0880],\n",
       "         [ 0.0252,  0.0278,  0.1402, -0.1567, -0.0886,  0.0320,  0.2092, -0.1916,\n",
       "           0.2120, -0.1528,  0.1569,  0.1315, -0.1469, -0.1962,  0.0763, -0.1062,\n",
       "           0.0937, -0.0926, -0.0758,  0.1865],\n",
       "         [ 0.0086, -0.0257, -0.0097,  0.1973, -0.1210, -0.0935,  0.1735, -0.1644,\n",
       "           0.0030, -0.1249, -0.0033,  0.1789, -0.0548,  0.2137,  0.1253,  0.1511,\n",
       "          -0.2066, -0.1164, -0.0658,  0.1530],\n",
       "         [-0.1431,  0.0753,  0.0163,  0.0393,  0.1437,  0.0045, -0.0790, -0.1866,\n",
       "           0.0604,  0.1212, -0.0738,  0.1627, -0.1879, -0.0519, -0.0821,  0.0293,\n",
       "           0.0941,  0.2002,  0.2052,  0.0487]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.1535,  0.2159,  0.1678, -0.1466,  0.0177], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.4538e-02, -2.9768e-01,  7.3386e-02,  3.9477e-01, -3.6105e-01],\n",
       "         [-7.7216e-02,  1.9951e-01,  3.5409e-01,  4.7554e-02, -3.8926e-01],\n",
       "         [-6.3154e-03,  3.1707e-01, -4.0630e-01,  1.2407e-01,  3.3809e-02],\n",
       "         [-3.6838e-01,  4.3691e-01, -4.1084e-01, -3.4214e-01,  5.6758e-02],\n",
       "         [ 3.4202e-01, -7.0121e-02,  9.5040e-02, -3.5242e-01, -4.7982e-02],\n",
       "         [-7.4864e-02,  2.5638e-01,  3.9684e-01,  4.0845e-01,  2.3080e-01],\n",
       "         [-2.1643e-01, -3.6418e-01,  2.6338e-01, -3.4651e-01, -4.3894e-01],\n",
       "         [-9.1562e-02,  2.3733e-01,  3.7894e-01,  2.5862e-01, -7.2191e-02],\n",
       "         [-2.0700e-01, -3.3999e-01, -1.4197e-01, -1.6638e-01,  3.8796e-01],\n",
       "         [-1.9043e-01,  6.1009e-02, -2.2275e-01,  2.1454e-01,  1.8832e-01],\n",
       "         [ 4.4187e-01, -3.0597e-01,  4.3247e-01, -3.7949e-02, -1.4606e-01],\n",
       "         [-4.1149e-01,  3.0402e-01, -8.0601e-02,  1.4637e-01, -1.0255e-01],\n",
       "         [-3.5041e-01,  1.8459e-01, -2.3770e-01, -2.3881e-01,  2.7659e-01],\n",
       "         [ 1.0106e-01,  1.3953e-01, -8.5797e-02,  7.7465e-02,  2.7961e-01],\n",
       "         [ 8.3164e-02, -3.9132e-01, -1.1088e-01, -1.8516e-01, -1.8899e-04],\n",
       "         [ 1.5461e-02,  1.9481e-01, -4.2291e-01,  2.7196e-01,  2.9974e-01],\n",
       "         [ 4.0722e-01, -1.1047e-01,  4.3975e-01, -2.1032e-01,  1.3342e-01],\n",
       "         [-3.6790e-01,  2.5706e-01, -4.3909e-01, -1.4061e-01, -2.6077e-01],\n",
       "         [-1.1294e-01, -2.1394e-01, -5.6601e-02, -3.9612e-01,  1.3088e-01],\n",
       "         [ 2.0924e-01, -1.5640e-02, -4.3776e-01,  3.5826e-01, -4.3208e-01],\n",
       "         [ 1.9647e-01,  4.1241e-01,  4.4049e-01,  9.2634e-02, -4.2767e-01],\n",
       "         [ 4.5124e-02,  1.5069e-01,  2.6461e-01,  2.1714e-01,  1.5546e-01],\n",
       "         [-2.4243e-01, -3.9804e-01,  6.5226e-02,  1.0088e-01, -1.3576e-01],\n",
       "         [-2.6192e-01,  4.3491e-01,  2.9420e-01, -3.3558e-01, -3.0875e-01],\n",
       "         [-3.8450e-02,  3.2777e-01,  2.9337e-01,  1.4960e-01,  3.5580e-01],\n",
       "         [ 3.7332e-01,  2.0258e-01, -2.2711e-01, -1.4836e-02,  1.5670e-01],\n",
       "         [-2.7469e-01, -1.2477e-01, -8.2319e-02, -1.0024e-01, -3.1015e-01],\n",
       "         [ 1.0569e-01,  2.1298e-01, -2.7214e-01, -1.5992e-02,  1.8521e-01],\n",
       "         [-4.4182e-01, -5.7142e-02, -2.3756e-01,  1.4796e-01,  4.4117e-01],\n",
       "         [-7.5323e-03,  3.6325e-01, -4.1323e-01,  3.1697e-01,  1.6152e-01],\n",
       "         [-3.4361e-01,  3.6793e-01,  1.1968e-01, -1.8414e-01, -1.4375e-01],\n",
       "         [-3.9036e-01, -3.6833e-01, -2.3331e-01,  3.3624e-01,  3.0236e-01],\n",
       "         [-1.5238e-01, -1.9694e-01,  2.8494e-01,  2.3582e-01, -1.1459e-01],\n",
       "         [-1.1759e-01,  3.5919e-01,  4.8431e-03, -4.6447e-02,  2.5212e-01],\n",
       "         [-2.5346e-01,  4.2688e-01,  3.5437e-01, -2.7922e-01, -4.3334e-01],\n",
       "         [-2.3653e-01, -4.2903e-02,  4.4403e-01,  2.0775e-01,  3.9588e-01],\n",
       "         [ 3.1807e-01,  1.6166e-02, -1.3244e-01,  3.4870e-01,  1.1649e-01],\n",
       "         [ 7.6479e-02, -3.2250e-02,  2.7655e-01,  4.1498e-01,  1.5198e-01],\n",
       "         [-1.8303e-01,  4.9498e-02, -1.6417e-01,  1.8891e-01, -4.2782e-01],\n",
       "         [-1.2613e-01,  2.9432e-01, -2.4526e-01,  2.2139e-01,  1.1503e-01],\n",
       "         [ 2.6749e-01,  4.2131e-01, -6.7576e-02, -3.6208e-01, -3.0389e-01],\n",
       "         [ 1.9074e-01,  4.3625e-01,  4.2986e-01,  1.4557e-01, -4.1138e-01],\n",
       "         [-3.4647e-01,  3.2215e-01, -4.6355e-02,  3.0771e-01,  2.7887e-01],\n",
       "         [-3.5498e-01, -3.0309e-01,  2.3638e-01,  2.4301e-01,  3.8885e-01],\n",
       "         [ 3.6106e-01,  2.2291e-01, -4.2577e-01, -4.3905e-02, -4.3268e-02],\n",
       "         [ 4.0130e-01, -1.2251e-01,  2.9603e-01,  3.9903e-01,  4.3810e-01],\n",
       "         [ 5.8429e-02, -6.0153e-02,  1.9599e-01, -4.2978e-01,  2.2554e-01],\n",
       "         [-5.9763e-03, -2.8304e-01, -7.6958e-02,  2.2142e-01, -1.9698e-01],\n",
       "         [ 1.8221e-01, -3.4439e-01, -3.0565e-01,  3.1639e-01, -3.4150e-01],\n",
       "         [ 3.1119e-01, -1.5874e-01, -2.6160e-02,  3.3157e-01, -1.2056e-01],\n",
       "         [-3.9708e-01, -4.1437e-01,  1.6751e-01, -2.8602e-02,  3.1533e-01],\n",
       "         [-3.8455e-01, -1.3514e-01,  7.8916e-02, -2.5212e-01, -1.0526e-01],\n",
       "         [-1.4993e-01,  3.0050e-01, -8.1649e-02, -4.3607e-01, -3.5563e-01],\n",
       "         [-3.9194e-01,  8.8110e-02, -3.8527e-01,  2.9982e-01,  1.5143e-01],\n",
       "         [-2.3349e-01, -2.9401e-01, -1.6934e-01,  6.2234e-03, -2.6061e-01],\n",
       "         [-1.2986e-02,  1.5304e-01,  1.5480e-01,  1.2642e-01, -2.5500e-01],\n",
       "         [-4.2895e-02,  4.6802e-02, -4.1978e-01, -8.5761e-02,  2.5733e-01],\n",
       "         [-1.8985e-01, -2.1544e-01,  3.0026e-01, -1.6622e-01, -1.6161e-01],\n",
       "         [ 3.1195e-02, -1.9143e-01,  2.2803e-01,  6.4835e-02,  4.1445e-01],\n",
       "         [ 2.4000e-02, -1.8299e-01,  5.4608e-02,  9.0429e-02,  1.5940e-01],\n",
       "         [ 1.0117e-01, -2.7627e-01,  6.0300e-03,  4.5014e-02,  9.5831e-02],\n",
       "         [-3.3663e-01,  3.8798e-01, -8.4302e-02, -4.1611e-01,  2.0593e-01],\n",
       "         [-1.0653e-01,  4.2160e-01,  9.7399e-02, -4.3328e-01,  3.1188e-01],\n",
       "         [ 3.0802e-01,  4.0792e-01,  2.4839e-01, -2.5153e-01, -3.2462e-01],\n",
       "         [-6.1771e-02, -3.4019e-01, -4.2925e-01, -2.0335e-01,  4.1128e-01],\n",
       "         [-8.6479e-02,  2.1701e-01,  4.0331e-01,  7.9711e-02, -3.7087e-01],\n",
       "         [-3.7641e-01,  2.6401e-01, -1.4839e-01,  4.1701e-01,  2.6600e-01],\n",
       "         [ 3.6026e-01,  4.2113e-01,  3.4565e-02,  3.2957e-01, -4.9558e-02],\n",
       "         [ 1.6452e-01,  4.2762e-01, -2.2870e-01,  9.1323e-05, -3.3890e-01],\n",
       "         [-2.1019e-01, -2.9130e-01,  3.8672e-01, -4.1222e-01,  1.0379e-01],\n",
       "         [-8.1244e-02,  4.1857e-01,  7.2700e-03,  8.1396e-02,  2.6939e-01],\n",
       "         [-3.4503e-01, -4.1301e-02,  7.1232e-03,  4.8293e-02,  3.8692e-01],\n",
       "         [ 1.8767e-01,  2.6975e-01, -1.1043e-01, -3.1212e-01,  3.7008e-01],\n",
       "         [-1.4203e-02,  4.3857e-01,  6.3323e-02,  3.1678e-01, -3.8661e-01],\n",
       "         [ 3.5844e-02,  2.7897e-01, -2.5026e-02, -6.9260e-02, -4.4682e-01],\n",
       "         [-2.1354e-01, -1.2443e-02,  3.1878e-01, -2.7905e-02, -2.2928e-01],\n",
       "         [ 5.7374e-03, -2.8291e-02,  3.5514e-01,  1.6975e-01,  2.4194e-01],\n",
       "         [ 2.2269e-01, -3.0019e-01, -2.6362e-01,  1.5167e-01, -1.7202e-01],\n",
       "         [-2.6685e-01, -4.4287e-01,  2.9664e-01,  3.4646e-01, -2.6889e-01],\n",
       "         [ 6.2096e-02, -6.1113e-02, -2.7758e-01, -1.3441e-01, -2.3320e-01],\n",
       "         [-2.7904e-01,  3.7431e-01,  4.2979e-01,  1.8701e-01, -2.8479e-01],\n",
       "         [-2.0900e-01, -1.3713e-01,  4.1479e-01,  2.7463e-01, -2.9018e-02],\n",
       "         [ 5.4045e-02,  3.1193e-01,  1.6130e-01, -6.0962e-02,  3.8550e-01],\n",
       "         [ 3.6355e-01,  3.4106e-02,  1.6120e-01, -3.2733e-01, -9.4601e-02],\n",
       "         [ 8.7064e-02,  1.2594e-01, -2.5765e-01,  4.0413e-01, -3.2474e-01],\n",
       "         [-3.6330e-01, -1.1167e-01,  2.2716e-01,  2.3219e-01,  2.0079e-02],\n",
       "         [ 6.9412e-02, -7.3208e-03,  3.8685e-01, -4.0720e-01,  1.8973e-01],\n",
       "         [-3.3383e-01,  3.6417e-01,  2.5446e-01, -3.4438e-01,  1.7362e-01],\n",
       "         [-1.7935e-02,  4.0155e-01,  1.2339e-01, -3.7030e-01, -3.3267e-01],\n",
       "         [ 2.4450e-01,  1.6490e-01,  1.1549e-01,  1.9591e-01, -4.0403e-01],\n",
       "         [-2.6146e-01,  3.5310e-01,  1.4114e-01,  1.0997e-01,  1.9789e-01],\n",
       "         [ 1.5700e-01, -1.6980e-01,  1.8579e-01,  1.9350e-01, -1.8187e-01],\n",
       "         [-2.8412e-01, -4.3213e-01, -1.2357e-01, -3.5989e-01,  1.1958e-01],\n",
       "         [ 1.0195e-01, -3.1615e-01,  2.7059e-01, -1.1687e-01, -1.6514e-01],\n",
       "         [-2.1573e-01, -4.2381e-01, -3.7566e-01,  9.7729e-02, -1.6164e-02],\n",
       "         [ 1.1518e-02,  3.7117e-01, -2.5269e-03, -3.0406e-01, -4.4697e-01],\n",
       "         [-1.6608e-01,  2.9900e-01, -2.5131e-01,  3.1585e-01,  3.2554e-01],\n",
       "         [ 3.0161e-01,  3.8252e-01, -3.4902e-01,  3.1080e-01,  3.8852e-01],\n",
       "         [ 3.2103e-01,  1.1189e-01, -3.5007e-01,  4.4001e-01, -2.8574e-01],\n",
       "         [-2.6768e-01,  6.5647e-02, -3.1506e-01, -1.9219e-01, -2.5504e-01]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.1140,  0.3136, -0.4306,  0.3785, -0.4320, -0.3654, -0.0624,  0.3259,\n",
       "         -0.1576, -0.2448, -0.1573,  0.0656,  0.1602,  0.0855, -0.2754, -0.4192,\n",
       "          0.4387,  0.2815, -0.4146,  0.1531, -0.1435,  0.4006,  0.2540, -0.2802,\n",
       "          0.0379, -0.1222, -0.2630,  0.3279,  0.3740, -0.2949,  0.0394, -0.3087,\n",
       "         -0.2606,  0.1279,  0.4261, -0.4346,  0.1624,  0.0922,  0.2017, -0.3985,\n",
       "          0.4253,  0.2381,  0.3979,  0.2645, -0.2455,  0.2746,  0.1947,  0.1315,\n",
       "          0.3274, -0.4122, -0.1688,  0.0415, -0.0312, -0.2885,  0.2252,  0.2757,\n",
       "          0.3350, -0.2752, -0.2076, -0.0774, -0.2912, -0.0787, -0.2936, -0.2916,\n",
       "         -0.0396, -0.0643,  0.0553,  0.1647, -0.2845,  0.2963,  0.0328,  0.0723,\n",
       "         -0.3948, -0.0586, -0.2805,  0.3450,  0.1338, -0.1932, -0.0902, -0.0298,\n",
       "          0.2465, -0.4008, -0.1695, -0.4053,  0.1272, -0.1306, -0.2093, -0.2796,\n",
       "          0.3833, -0.0061, -0.4471,  0.3123, -0.1084, -0.2738, -0.4325, -0.0264,\n",
       "         -0.0675, -0.2419, -0.2063,  0.3767], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0239,  0.0489, -0.0663,  ...,  0.0782, -0.0871, -0.0270],\n",
       "         [-0.0278, -0.0601,  0.0210,  ..., -0.0819, -0.0821,  0.0905],\n",
       "         [ 0.0768,  0.0610,  0.0390,  ...,  0.0550,  0.0557, -0.0601],\n",
       "         ...,\n",
       "         [-0.0480, -0.0136, -0.0934,  ...,  0.0371,  0.0085, -0.0795],\n",
       "         [ 0.0524, -0.0226, -0.0317,  ...,  0.0090,  0.0783, -0.0567],\n",
       "         [ 0.0973, -0.0465, -0.0119,  ..., -0.0235, -0.0046, -0.0169]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0639, -0.0994,  0.0990,  0.0096,  0.0332,  0.0803,  0.0796,  0.0032,\n",
       "          0.0578, -0.0766,  0.0466, -0.0335, -0.0817, -0.0984,  0.0307, -0.0051,\n",
       "          0.0006,  0.0688, -0.0581,  0.0563,  0.0909,  0.0501,  0.0017,  0.0786,\n",
       "          0.0619, -0.0338,  0.0674, -0.0932, -0.0332, -0.0063,  0.0278, -0.0781,\n",
       "          0.0926, -0.0087, -0.0885,  0.0985, -0.0644, -0.0242,  0.0423, -0.0497,\n",
       "         -0.0736, -0.0180,  0.0847,  0.0318, -0.0963,  0.0822, -0.0616,  0.0007,\n",
       "         -0.0414,  0.0536,  0.0734, -0.0890,  0.0296, -0.0368, -0.0948,  0.0825,\n",
       "          0.0771,  0.0529, -0.0385,  0.0341, -0.0057,  0.0387, -0.0921, -0.0410,\n",
       "          0.0772,  0.0234, -0.0093, -0.0249,  0.0597,  0.0734, -0.0710,  0.0905,\n",
       "         -0.0331, -0.0604,  0.0414,  0.0491,  0.0124, -0.0416,  0.0688,  0.0026,\n",
       "         -0.0431, -0.0427, -0.0391,  0.0216,  0.0035, -0.0954, -0.0349, -0.0891,\n",
       "         -0.0393,  0.0663, -0.0691, -0.0020, -0.0319, -0.0881,  0.0077,  0.0733,\n",
       "         -0.0276,  0.0125,  0.0387,  0.0201, -0.0716,  0.0599,  0.0433,  0.0304,\n",
       "         -0.0881,  0.0467, -0.0848,  0.0328,  0.0075,  0.0558,  0.0098, -0.0273,\n",
       "          0.0884,  0.0558,  0.0929,  0.0687, -0.0929, -0.0795, -0.0938, -0.0829,\n",
       "         -0.0660, -0.0092,  0.0787, -0.0158, -0.0496,  0.0946, -0.0129,  0.0243,\n",
       "         -0.0733, -0.0077, -0.0629,  0.0378, -0.0092, -0.0731,  0.0353,  0.0978,\n",
       "          0.0038, -0.0181,  0.0964,  0.0795, -0.0238, -0.0326,  0.0606, -0.0139,\n",
       "          0.0367,  0.0698, -0.0847,  0.0715, -0.0121, -0.0972,  0.0362, -0.0049,\n",
       "         -0.0415, -0.0302,  0.0131,  0.0817, -0.0442, -0.0094, -0.0580,  0.0538,\n",
       "          0.0168,  0.0887,  0.0524, -0.0541,  0.0976,  0.0556,  0.0211,  0.0772,\n",
       "          0.0105, -0.0210, -0.0932, -0.0917,  0.0053, -0.0012, -0.0683, -0.0688,\n",
       "         -0.0890,  0.0200,  0.0426, -0.0597,  0.0900, -0.0059, -0.0989, -0.0721,\n",
       "         -0.0269,  0.0646, -0.0323,  0.0652,  0.0923, -0.0324,  0.0052,  0.0334,\n",
       "         -0.0212,  0.0314,  0.0317,  0.0425,  0.0085, -0.0951,  0.0861, -0.0445,\n",
       "         -0.0947, -0.0866,  0.0827, -0.0643,  0.0040, -0.0215,  0.0119,  0.0187,\n",
       "         -0.0559, -0.0495, -0.0260, -0.0828, -0.0504, -0.0780, -0.0815,  0.0439,\n",
       "          0.0855, -0.0148,  0.0669, -0.0137,  0.0452, -0.0189, -0.0687, -0.0960,\n",
       "         -0.0492,  0.0589,  0.0049,  0.0724,  0.0860, -0.0228, -0.0004, -0.0752,\n",
       "         -0.0683,  0.0175, -0.0930,  0.0290, -0.0778,  0.0222, -0.0324, -0.0272,\n",
       "          0.0515,  0.0029,  0.0992, -0.0340,  0.0636,  0.0989, -0.0774,  0.0595,\n",
       "          0.0480,  0.0530,  0.0674,  0.0153,  0.0010, -0.0834,  0.0714, -0.0115,\n",
       "          0.0154, -0.0487, -0.0169, -0.0281, -0.0367,  0.0415, -0.0094, -0.0951,\n",
       "          0.0852, -0.0915, -0.0178,  0.0481,  0.0114,  0.0998, -0.0123,  0.0698,\n",
       "          0.0588, -0.0477, -0.0168, -0.0238,  0.0889,  0.0102, -0.0366, -0.0739,\n",
       "         -0.0610, -0.0017, -0.0831, -0.0619, -0.0236, -0.0822,  0.0330, -0.0992,\n",
       "          0.0294,  0.0096,  0.0560,  0.0983,  0.0849,  0.0954, -0.0207, -0.0662,\n",
       "         -0.0300, -0.0362, -0.0425,  0.0850, -0.0341, -0.0410, -0.0648, -0.0124,\n",
       "          0.0310,  0.0359, -0.0605, -0.0091, -0.0497, -0.0054,  0.0768, -0.0420,\n",
       "         -0.0910, -0.0604,  0.0649,  0.0115,  0.0194,  0.0469,  0.0043, -0.0911,\n",
       "          0.0291, -0.0589,  0.0034, -0.0181,  0.0767,  0.0382, -0.0386, -0.0870,\n",
       "         -0.0789,  0.0269,  0.0508, -0.0510,  0.0544,  0.0115,  0.0476,  0.0808,\n",
       "         -0.0565,  0.0015,  0.0597, -0.0083,  0.0194,  0.0341, -0.0346, -0.0057,\n",
       "          0.0929, -0.0037,  0.0163,  0.0630, -0.0293, -0.0848,  0.0139, -0.0328,\n",
       "         -0.0317, -0.0539, -0.0730,  0.0514,  0.0408, -0.0253,  0.0209, -0.0799,\n",
       "          0.0176, -0.0794, -0.0457, -0.0296, -0.0736, -0.0383,  0.0874, -0.0719,\n",
       "          0.0108,  0.0432,  0.0296, -0.0698,  0.0672,  0.0533, -0.0974,  0.0769,\n",
       "         -0.0713,  0.0287, -0.0063, -0.0341,  0.0040,  0.0019, -0.0127, -0.0266,\n",
       "          0.0489,  0.0578, -0.0699, -0.0179,  0.0551,  0.0603, -0.0542, -0.0567,\n",
       "          0.0422, -0.0130, -0.0533, -0.0263,  0.0984,  0.0508, -0.0208, -0.0333,\n",
       "          0.0258, -0.0514, -0.0939,  0.0562, -0.0021,  0.0991, -0.0554,  0.0621,\n",
       "          0.0187, -0.0287,  0.0772, -0.0531, -0.0689,  0.0038, -0.0561, -0.0254,\n",
       "         -0.0540,  0.0086,  0.0704,  0.0414,  0.0061, -0.0677, -0.0677,  0.0680,\n",
       "          0.0344, -0.0292,  0.0567, -0.0035,  0.0466,  0.0652, -0.0661,  0.0855,\n",
       "          0.0131,  0.0174, -0.0211, -0.0073, -0.0975, -0.0178, -0.0069,  0.0533,\n",
       "         -0.0515, -0.0401,  0.0617, -0.0711,  0.0716,  0.0107, -0.0233, -0.0476,\n",
       "          0.0233,  0.0323, -0.0461,  0.0568,  0.0238,  0.0354, -0.0963,  0.0858,\n",
       "          0.0595,  0.0257, -0.0729,  0.0819,  0.0221,  0.0101, -0.0007,  0.0022,\n",
       "          0.0590, -0.0831,  0.0015, -0.0581, -0.0262,  0.0867,  0.0172,  0.0418,\n",
       "         -0.0339, -0.0275, -0.0352,  0.0698,  0.0408, -0.0001, -0.0972, -0.0687,\n",
       "          0.0022, -0.0687, -0.0301, -0.0603,  0.0004, -0.0313, -0.0506,  0.0454,\n",
       "         -0.0397, -0.0463, -0.0554,  0.0217,  0.0229,  0.0489,  0.0485,  0.0789,\n",
       "          0.0689,  0.0701, -0.0231, -0.0012,  0.0871, -0.0874, -0.0882, -0.0437,\n",
       "         -0.0834,  0.0480, -0.0946,  0.0678, -0.0111,  0.0465,  0.0315, -0.0520,\n",
       "          0.0573, -0.0399, -0.0165,  0.0540,  0.0007, -0.0307, -0.0413, -0.0829,\n",
       "          0.0101, -0.0068, -0.0071,  0.0024, -0.0554,  0.0003, -0.0150,  0.0619,\n",
       "          0.0215, -0.0818,  0.0787, -0.0810, -0.0823, -0.0709, -0.0765, -0.0955,\n",
       "          0.0691,  0.0348,  0.0358,  0.0062, -0.0694,  0.0895,  0.0382, -0.0638,\n",
       "         -0.0582, -0.0366,  0.0007, -0.0958, -0.0105,  0.0138, -0.0635,  0.0459,\n",
       "          0.0343,  0.0217,  0.0911, -0.0526,  0.0783, -0.0449,  0.0147,  0.0770,\n",
       "          0.0737, -0.0672,  0.0983, -0.0160,  0.0743, -0.0638, -0.0512, -0.0669,\n",
       "          0.0902, -0.0105,  0.0767,  0.0509,  0.0853,  0.0486,  0.0111, -0.0042,\n",
       "          0.0151, -0.0342,  0.0096,  0.0549, -0.0791,  0.0467,  0.0827, -0.0297,\n",
       "          0.0680,  0.0520,  0.0418, -0.0133,  0.0963,  0.0685, -0.0176, -0.0124,\n",
       "          0.0349,  0.0084,  0.0152, -0.0499,  0.0193,  0.0844, -0.0158, -0.0407,\n",
       "          0.0606,  0.0472,  0.0072,  0.0989,  0.0154, -0.0958, -0.0629,  0.0250,\n",
       "         -0.0222,  0.0357, -0.0807, -0.0999,  0.0803,  0.0170, -0.0728,  0.0771,\n",
       "          0.0718, -0.0502, -0.0163,  0.0740, -0.0213,  0.0184,  0.0547, -0.0634,\n",
       "          0.0688, -0.0853, -0.0053, -0.0937, -0.0304, -0.0383, -0.0365,  0.0103,\n",
       "         -0.0098, -0.0152, -0.0287,  0.0010, -0.0086,  0.0614, -0.0391,  0.0650,\n",
       "          0.0224,  0.0622,  0.0934, -0.0402, -0.0624,  0.0624,  0.0454,  0.0454,\n",
       "          0.0411, -0.0049, -0.0598,  0.0970, -0.0230, -0.0887, -0.0371, -0.0387,\n",
       "         -0.0929, -0.0832, -0.0867,  0.0871,  0.0667, -0.0174, -0.0553,  0.0465,\n",
       "         -0.0746, -0.0492, -0.0400, -0.0785,  0.0964,  0.0432, -0.0436,  0.0332,\n",
       "          0.0715,  0.0768,  0.0312,  0.0115,  0.0486,  0.0704,  0.0910, -0.0772,\n",
       "          0.0476, -0.0041,  0.0478, -0.0720,  0.0975, -0.0067,  0.0434,  0.0271,\n",
       "         -0.0633, -0.0123,  0.0531,  0.0435,  0.0353,  0.0866, -0.0896, -0.0983,\n",
       "          0.0097, -0.0455, -0.0038,  0.0998, -0.0482,  0.0551, -0.0890, -0.0244,\n",
       "          0.0168, -0.0741, -0.0779,  0.0302,  0.0217,  0.0982,  0.0987,  0.0985,\n",
       "         -0.0517,  0.0036, -0.0734, -0.0053, -0.0285, -0.0974, -0.0651, -0.0561,\n",
       "         -0.0749,  0.0182,  0.0395, -0.0910,  0.0683, -0.0752,  0.0099, -0.0180,\n",
       "         -0.0035, -0.0175, -0.0734, -0.0113, -0.0496, -0.0382, -0.0601,  0.0198,\n",
       "         -0.0274,  0.0874,  0.0047, -0.0172,  0.0679,  0.0762, -0.0956, -0.0923,\n",
       "         -0.0590, -0.0922, -0.0489, -0.0383,  0.0728,  0.0225,  0.0691,  0.0674,\n",
       "          0.0108,  0.0117,  0.0467,  0.0872, -0.0928, -0.0325,  0.0999, -0.0206,\n",
       "         -0.0652, -0.0506,  0.0071, -0.0127,  0.0692,  0.0102,  0.0718, -0.0078,\n",
       "         -0.0440,  0.0646,  0.0717, -0.0947,  0.0424, -0.0645,  0.0305,  0.0506,\n",
       "          0.0636, -0.0539, -0.0527, -0.0466, -0.0850, -0.0611, -0.0316,  0.0032],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0729,  0.0652,  0.0591,  ..., -0.0033, -0.0288, -0.0046],\n",
       "         [ 0.0529, -0.0082, -0.0374,  ..., -0.0851,  0.0888, -0.0962],\n",
       "         [-0.0382,  0.0296,  0.0122,  ..., -0.0486,  0.0239, -0.0312],\n",
       "         ...,\n",
       "         [ 0.0151,  0.0462,  0.0311,  ..., -0.0169,  0.0352,  0.0724],\n",
       "         [-0.0322,  0.0840, -0.0933,  ..., -0.0775,  0.0135,  0.0148],\n",
       "         [-0.0213,  0.0985, -0.0054,  ...,  0.0848,  0.0132, -0.0711]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0027, -0.0557,  0.0406, -0.0874,  0.0189,  0.0959, -0.0886, -0.0277,\n",
       "         -0.0555,  0.0767,  0.0806,  0.0691, -0.0505,  0.0089,  0.0893,  0.0892,\n",
       "          0.0934, -0.0175,  0.0271,  0.0044, -0.0578,  0.0140, -0.0933,  0.0966,\n",
       "         -0.0722,  0.0703,  0.0796,  0.0013,  0.0373, -0.0617, -0.0599,  0.0292,\n",
       "          0.0634, -0.0453,  0.0893,  0.0448,  0.0569,  0.0202,  0.0266, -0.0472,\n",
       "          0.0136,  0.0380,  0.0272,  0.0470, -0.0687, -0.0120,  0.0231,  0.0123,\n",
       "          0.0991,  0.0508,  0.0915,  0.0989, -0.0065, -0.0291, -0.0603, -0.0905,\n",
       "          0.0698,  0.0324, -0.0543,  0.0621,  0.0109, -0.0749, -0.0682, -0.0133,\n",
       "         -0.0408, -0.0572, -0.0443,  0.0138,  0.0366,  0.0643, -0.0805,  0.0358,\n",
       "          0.0940, -0.0670,  0.0680,  0.0860,  0.0739, -0.0432, -0.0207, -0.0786,\n",
       "          0.0223,  0.0699,  0.0210,  0.0969, -0.0074,  0.0276, -0.0091, -0.0317,\n",
       "         -0.0140, -0.0281, -0.0649, -0.0825,  0.0414,  0.0799,  0.0470,  0.0570,\n",
       "          0.0313,  0.0095, -0.0602,  0.0248, -0.0186, -0.0220, -0.0196, -0.0259,\n",
       "         -0.0464,  0.0192, -0.0581, -0.0545, -0.0693,  0.0879, -0.0713, -0.0144,\n",
       "          0.0608,  0.0493,  0.0839,  0.0862,  0.0689,  0.0856, -0.0332, -0.0468,\n",
       "          0.0398, -0.0815,  0.0584,  0.0547, -0.0083,  0.0782, -0.0425, -0.0856,\n",
       "         -0.0831, -0.0624, -0.0362, -0.0748, -0.0489, -0.0985,  0.0790,  0.0977,\n",
       "          0.0172, -0.0397,  0.0591,  0.0306,  0.0867,  0.0139, -0.0886, -0.0657,\n",
       "         -0.0974, -0.0111, -0.0358,  0.0816,  0.0803,  0.0643, -0.0769,  0.0375,\n",
       "         -0.0460, -0.0618,  0.0667,  0.0689, -0.0195,  0.0259,  0.0058, -0.0539,\n",
       "          0.0360,  0.0761,  0.0288,  0.0100,  0.0925,  0.0361,  0.0967,  0.0393,\n",
       "         -0.0970,  0.0889, -0.0896,  0.0368,  0.0575,  0.0949,  0.0607,  0.0767,\n",
       "         -0.0147,  0.0203, -0.0262, -0.0781,  0.0767, -0.0148,  0.0961, -0.0560,\n",
       "          0.0292, -0.0242, -0.0564,  0.0828, -0.0851, -0.0518, -0.0092,  0.0190,\n",
       "         -0.0527,  0.0046, -0.0519,  0.0983,  0.0966, -0.0959,  0.0402, -0.0477,\n",
       "          0.0911, -0.0848,  0.0964, -0.0665, -0.0413,  0.0039, -0.0792, -0.0077,\n",
       "         -0.0489,  0.0993,  0.0374, -0.0484,  0.0394, -0.0099, -0.0058,  0.0126,\n",
       "          0.0951,  0.0816, -0.0347, -0.0645, -0.0975,  0.0246, -0.0899,  0.0663,\n",
       "          0.0260, -0.0394, -0.0991, -0.0999, -0.0580, -0.0984, -0.0734,  0.0938,\n",
       "          0.0206, -0.0148,  0.0389, -0.0635, -0.0256,  0.0311,  0.0966, -0.0475,\n",
       "         -0.0489,  0.0608,  0.0470, -0.0453,  0.0918, -0.0978,  0.0200, -0.0596,\n",
       "          0.0434, -0.0195,  0.0778, -0.0112,  0.0785,  0.0408,  0.0303,  0.0878,\n",
       "          0.0249,  0.0208, -0.0950, -0.0769,  0.0571,  0.0149, -0.0720,  0.0973,\n",
       "         -0.0869, -0.0242, -0.0898, -0.0554,  0.0926, -0.0418, -0.0536,  0.0427,\n",
       "         -0.0230, -0.0916, -0.0920, -0.0277, -0.0938, -0.0805,  0.0648, -0.0391,\n",
       "         -0.0631,  0.0535, -0.0494, -0.0111, -0.0339, -0.0836,  0.0363,  0.0319,\n",
       "         -0.0756, -0.0514,  0.0995, -0.0150,  0.0298,  0.0292,  0.0075, -0.0499,\n",
       "          0.0136,  0.0657,  0.0267,  0.0020,  0.0778, -0.0903,  0.0663,  0.0400,\n",
       "         -0.0700,  0.0661,  0.0144,  0.0941,  0.0440, -0.0187, -0.0764, -0.0703,\n",
       "         -0.0543, -0.0961,  0.0336, -0.0051,  0.0672,  0.0172,  0.0452, -0.0231,\n",
       "         -0.0556, -0.0209, -0.0157, -0.0461, -0.0497,  0.0479,  0.0941, -0.0760,\n",
       "          0.0256, -0.0073, -0.0802, -0.0811,  0.0688,  0.0365,  0.0499, -0.0262,\n",
       "         -0.0115, -0.0265,  0.0635, -0.0608,  0.0807,  0.0938,  0.0864, -0.0989,\n",
       "          0.0668,  0.0473, -0.0516, -0.0405, -0.0208, -0.0032, -0.0923, -0.0597,\n",
       "          0.0544, -0.0533,  0.0618,  0.0494,  0.0041, -0.0502, -0.0109,  0.0839,\n",
       "         -0.0211, -0.0425, -0.0858, -0.0705, -0.0974, -0.0506,  0.0588,  0.0225,\n",
       "         -0.0835, -0.0192, -0.0930, -0.0663, -0.0323,  0.0908, -0.0826, -0.0124,\n",
       "          0.0947,  0.0459,  0.0983, -0.0704,  0.0448,  0.0830, -0.0294,  0.0019,\n",
       "          0.0465,  0.0943, -0.0234,  0.0420,  0.0791, -0.0545,  0.0952,  0.0880,\n",
       "         -0.0330,  0.0582, -0.0153,  0.0684, -0.0436,  0.0136, -0.0170, -0.0310,\n",
       "         -0.0096,  0.0084,  0.0285,  0.0098, -0.0323, -0.0810,  0.0048, -0.0439,\n",
       "         -0.0787, -0.0702, -0.0427,  0.0494,  0.0969,  0.0663, -0.0721, -0.0264,\n",
       "         -0.0707, -0.0793, -0.0070, -0.0635, -0.0647, -0.0061,  0.0335, -0.0004,\n",
       "          0.0958, -0.0758, -0.0824,  0.0457, -0.0660, -0.0718, -0.0885,  0.0505,\n",
       "         -0.0927, -0.0668,  0.0071, -0.0313,  0.0049, -0.0433,  0.0676, -0.0800,\n",
       "          0.0599, -0.0814,  0.0140, -0.0143,  0.0652,  0.0935,  0.0180,  0.0161,\n",
       "         -0.0251, -0.0038,  0.0539,  0.0685,  0.0435, -0.0244,  0.0241,  0.0090,\n",
       "         -0.0638, -0.0606,  0.0916,  0.0897, -0.0704, -0.0277, -0.0402, -0.0868,\n",
       "         -0.0440, -0.0187, -0.0283,  0.0902,  0.0059,  0.0043, -0.0060,  0.0780,\n",
       "          0.0861,  0.0772,  0.0177,  0.0605,  0.0241,  0.0903, -0.0750,  0.0509,\n",
       "         -0.0479, -0.0743,  0.0605, -0.0227, -0.0144,  0.0821, -0.0660, -0.0126,\n",
       "         -0.0499, -0.0657,  0.0923, -0.0241, -0.0739,  0.0046,  0.0544, -0.0357,\n",
       "          0.0936,  0.0711,  0.0598,  0.0315,  0.0604, -0.0076,  0.0970,  0.0921,\n",
       "         -0.0952,  0.0151, -0.0625, -0.0111, -0.0508,  0.0912, -0.0342,  0.0365,\n",
       "         -0.0199,  0.0065, -0.0504,  0.0945,  0.0626,  0.0473, -0.0210, -0.0314,\n",
       "          0.0473,  0.0949,  0.0154, -0.0910, -0.0905,  0.0603, -0.0178, -0.0997,\n",
       "         -0.0328,  0.0190,  0.0767,  0.0964, -0.0329,  0.0757,  0.0604,  0.0292,\n",
       "          0.0155,  0.0598, -0.0977,  0.0786,  0.0096, -0.0181, -0.0254,  0.0918,\n",
       "         -0.0270, -0.0404,  0.0395, -0.0864, -0.0226,  0.0281,  0.0251,  0.0303,\n",
       "          0.0652,  0.0691,  0.0918, -0.0659, -0.0586,  0.0324, -0.0303,  0.0102,\n",
       "         -0.0009, -0.0551,  0.0977,  0.0652,  0.0502,  0.0442, -0.0813, -0.0492,\n",
       "         -0.0252, -0.0674,  0.0347,  0.0760,  0.0717,  0.0788, -0.0974,  0.0888,\n",
       "          0.0702,  0.0793, -0.0434,  0.0310,  0.0319, -0.0585, -0.0716, -0.0870,\n",
       "         -0.0026,  0.0316, -0.0583, -0.0262,  0.0334,  0.0484,  0.0082, -0.0057,\n",
       "         -0.0002,  0.0159, -0.0304,  0.0027, -0.0411,  0.0805,  0.0382, -0.0788,\n",
       "          0.0223,  0.0905, -0.0707,  0.0689, -0.0733, -0.0379, -0.0664, -0.0551,\n",
       "          0.0566, -0.0777,  0.0917,  0.0258, -0.0365, -0.0020,  0.0734,  0.0889,\n",
       "         -0.1000, -0.0329, -0.0436,  0.0850,  0.0658,  0.0357, -0.0816,  0.0824,\n",
       "         -0.0081,  0.0333, -0.0522,  0.0787,  0.0028, -0.0579, -0.0257, -0.0420,\n",
       "         -0.0669, -0.0530, -0.0850, -0.0081, -0.0813,  0.0575,  0.0890, -0.0066,\n",
       "          0.0057, -0.0995,  0.0681, -0.0435, -0.0223, -0.0558, -0.0200,  0.0245,\n",
       "         -0.0885, -0.0093,  0.0196, -0.0199, -0.0775,  0.0173, -0.0118, -0.0404,\n",
       "          0.0453,  0.0411,  0.0335,  0.0682,  0.0959,  0.0472,  0.0448, -0.0245,\n",
       "          0.0706,  0.0691, -0.0796,  0.0282,  0.0606,  0.0555, -0.0803, -0.0367,\n",
       "          0.0580,  0.0598, -0.0149, -0.0565,  0.0879,  0.0227,  0.0442,  0.0029,\n",
       "          0.0546, -0.0405,  0.0544, -0.0877,  0.0938,  0.0074,  0.0153, -0.0217,\n",
       "         -0.0704,  0.0087,  0.0884, -0.0668, -0.0885, -0.0250, -0.0848, -0.0482,\n",
       "         -0.0126,  0.0714,  0.0358,  0.0076,  0.0999, -0.0776, -0.0876,  0.0366,\n",
       "          0.0282, -0.0419, -0.0164, -0.0686, -0.0056, -0.0982, -0.0587, -0.0298,\n",
       "         -0.0298, -0.0856, -0.0946, -0.0065, -0.0348,  0.0984,  0.0232,  0.0861,\n",
       "         -0.0207, -0.0650, -0.0811,  0.0263,  0.0785, -0.0532, -0.0704, -0.0936,\n",
       "         -0.0939,  0.0011,  0.0386,  0.0435,  0.0323, -0.0245,  0.0725,  0.0885,\n",
       "         -0.0921, -0.0753,  0.0367, -0.0003,  0.0841, -0.0246,  0.0073, -0.0602,\n",
       "         -0.0358, -0.0827,  0.0076,  0.0376,  0.0234,  0.0470,  0.0327,  0.0432,\n",
       "          0.0035, -0.0191, -0.0373,  0.0990, -0.0442, -0.0954,  0.0432,  0.0146,\n",
       "         -0.0441, -0.0384,  0.0613,  0.0470,  0.0395, -0.0813, -0.0577,  0.0451,\n",
       "         -0.0251,  0.0514, -0.0704, -0.0587,  0.0132, -0.0313, -0.0762, -0.0990,\n",
       "         -0.0883,  0.0604, -0.0912, -0.0397,  0.0278,  0.0084,  0.0346, -0.0049],\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vae.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_sample = vae(img_tens[0, :, :].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# !conda install -y matplotlib\n",
    "# display(rec_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x320c71850>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img_tens[0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x3230c0e30>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.imshow(torch.reshape(rec_sample, (28,28)).detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elbo(x_i, mu: Tensor, sigma: Tensor, log_prob: Tensor):\n",
    "    # TODO: implement log prob --> what is this? is this just the pdf evaluated at this point? \n",
    "    loss: Tensor = Tensor([0])\n",
    "    log_sigma_square: Tensor = torch.log(torch.square(sigma))\n",
    "    ones: Tensor = torch.ones(log_sigma_square.size())\n",
    "    mu_square: Tensor = torch.square(mu)\n",
    "    sigma_square: Tensor = torch.square(sigma)\n",
    "    return 1/2 * torch.sum(ones + log_sigma_square - mu_square - sigma_square) + log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data: Tensor, epochs: int, vae: VAE):\n",
    "    optim: torch.optim.Adam = torch.optim.Adam(params=vae.parameters(), lr=0.001)\n",
    "    enc: Encoder = vae.enc\n",
    "    dec: Decoder = vae.dec\n",
    "\n",
    "    xs: List = [] #TODO data add \n",
    "    for epoch in range(epochs):\n",
    "        for x in xs:\n",
    "            enc_mu_sigma: Tuple[Tensor, Tensor] = enc.__forward__(x)\n",
    "\n",
    "\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = torch.distributions.Normal(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3989])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(norm.log_prob(Tensor([0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-practice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
